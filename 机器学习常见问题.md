# 机器学习常见问题



#### 判断数据是否线性可分？

- 凸包（quickhull），检查边界是否相交（sweepLine）
- 用SVM、感知器测试线性可分性

#### 如果数据不是线性可分的？

把数据从低维映射到高维，转换为线性可分

#### 要保证模型效果，特征维度和样本数量的关系？



#### 数据样本数量较少，模型特征维度高，怎么办？

- 采集更多数据
- 数据增强
- 简单模型、先验模型
- 增加先验知识，做好特征工程
- 降维（PCA、LDA）
- 数据平衡

#### 为什么要进行标准化操作？哪些算法需要标准化操作？

- 正规化（z-score法）
  - 定义：对每一个数据减去均值再除以标准差（最后得到一个均值为0，标准差为1的数据）
  - 转化后的值范围可能大于1
  - 意义：
    - 一些算法对于数据的分布有前提假设（如满足正态分布等）
- 规范化（min_max法）
  - 定义：
  - 转化后的值范围在0到1之间
- 归一化（比例法）

标准化

正态分布

最大最小



#### 分类特征直接转换为数值特征有效吗？

#### 无效特征对模型的影响？什么模型或者什么方法可以减小无效特征的影响？或者如何发现无效特征？

#### 什么是高维稀疏特征？什么模型适合处理高维稀疏特征？

#### 特征每个维度要具有相似的取值范围/特征要归一化？

#### 特征选择

- 不同类型的特征有哪些？以及有哪些处理方法
- 

#### 模型选择：

- 不同模型，在训练集上得分越高越好吗？

  不是绝对的，在titanic比赛中，模型高分的反而在测试集上得分低

- 同一个模型，不同参数，在训练集上得分越高就越好吗？

  不是绝对的，在titanic比赛中，模型高分的反而在测试集上得分低

- 由此，很明显我们不能单凭训练集上的高分来选择模型作为我们的最佳模型用于新的数据；那么，我们应该如何去选择我们的最优模型呢？

  训练集上的得分最优不能作为根据的话，那么验证集上的得分是否可以呢？（此处猜测也不行）；那么是否有其它依据？

- 模型能做出好的预测一个前提是：测试数据和训练数据是同分布的

- 模型的训练误差和测试误差的关系是

  1. 随着训练误差减少，测试误差先减少后增大；对应的是模型从**欠拟合**到**最佳**到**过拟合，**也是偏差逐渐减小，方差逐渐增大的过程；因此我们需要找的是模型的一个平衡点，即偏差和方差的平衡点（证明偏差和方差的平衡点模型效果最佳？）

- 模型在训练集上的误差称为“训练误差”或“经验误差”

- 模型在测试集上的误差称为“泛化误差”，我们希望得到的是泛化误差最小的模型

#### 模型过拟合和欠拟合的解决方法

- 模型欠拟合（偏差大）：添加特征、提升模型复杂度；减小正则项权重
- 模型过拟合（方差大）：增加训练样本；降维；增加正则项权重

#### L1和L2正则化

#### 多重共线性

#### 不同类别样本不平衡的解决方法？

##### 采样

- 采样/过采样（

  数据生成

  ）

  - 随机过采样
  - SMOTE
    - 插值法生成新样本
    - Border-line SMOTE
    - SVM SMOTE
    - Kmeans SMOTE
    - SMOTE-NC
  - Adasyn

- 下采样/欠采样（

  数据抽样

  ）

  - 随机欠采样
  - EasyEnsemble
    - 多数类样本拆分成子集训练多个模型，然后集成模型
  - BalanceCascade
    - 抽样多数类结合少数类训练基学习器，然后利用Boosting迭代n轮，每轮剔除正确分类样本，使后面的基学习器更注重错分样本
  - NearMiss
    - 选择最具代表性的样本用于训练
  - Tomek Link
    - Link表示不同类别之间距离最近的一对样本：要么其中一个是噪音，要么两个样本均在边界上。
    - 通过移除Tomek Link，使得最近邻属于同一类别。
  - Edited Nearest
    - 对于多数类的一个样本，如果其K近邻超过某个阈值都不属于多数类，则剔除该样本

- 混合采样

##### 异常检测

- OneClassSVM

- iForest

- ...

##### 其它

- 迁移学习
- 元学习/域自适应
- 解耦特征和分类器
- 半监督/自监督
- 集成学习
- 损失函数
  - 类别加权Loss
  - Focal Loss
  - GHM Loss
- 评价指标
  - 不能单看准确率等一些单一指标，要分析实际需求
    - 性别识别：如果100个人里面有88个男的，那么分类器全估计男的就可以得到88%的准确率，显然是无意义的。
  - 可以使用PRC

#### 小样本和数据不均衡

- 适合样本数据量少的机器学习算法有哪些？
  - SVM
  - 朴素贝叶斯
  - 决策树
