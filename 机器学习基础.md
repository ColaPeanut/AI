# 机器学习

> 机器学习最重要的两个点：1. 数据质量  2. 特征工程

- garbage in, garbage out
- data is all
- 使用模型多步走：
  1. 模型主要应用于什么场景（分类/回归/...）？（或者当前的问题能否转换为当前模型的应用场景？）
  2. 模型使用前置条件（例如，基于数据独立同分布的假设）？
  3. 模型优缺点
  4. 模型原理
- 从经典论文出发，从基础出发，从相关课题出发。



# 基本概念

什么是机器学习？



机器学习的应用？



## 机器学习概览

### 按发展顺序分类

#### 经典的机器学习模型

- 感知机  Perception
- K近邻  KNN
- 朴素贝叶斯
- 决策树  Decision Tree
- 逻辑回归  Logistics Regression
- 最大熵  
- 支持向量机  SVM
- Apriori
- 集成算法
  - Voting(不同模型，投票法)
  - Bagging（相同模型，有放回抽样，投票法）
  - Pasting（相同模型，无放回抽样，投票法）
  - Boosting（）
  - Stacking（相同模型，加权投票法）
- 聚类
  - K均值  K-Means
  - ISODATA
  - 均值漂移  Mean-Shift
  - 亲和传播  Affinity Propagation
  - 光谱聚类  Spectral Clustering
  - DBSCAN
  - OPTICS
  - 层次聚类  Hierarchical Clustering
  - BIRTCH
- 降维
  - 奇异值分解  SVD
  - 主成分分析  PCA
  - 线性判别分析  LDA

- EM算法
- 隐马尔可夫模型
- 条件随机场



#### 深度学习模型

- 卷积神经网络
- 循环神经网络
- 强化学习
- 生成式对抗网络
- 迁移学习



### 按学习任务/用途分类

#### 分类/聚类



#### 回归



#### 标注



#### 降维



### 按学习方式分类

#### 监督学习/半监督学习/无监督学习/强化学习



#### 批量学习/在线学习



#### 基于实例的学习/基于模型的学习



### 按模型分类

#### 生成式模型



#### 判别式模型



# 数学基础

## 概率论



## 线性代数



## 微积分





# 机器学习基本流程

## 明确目标

1. 背景是什么？
2. 解决什么问题？
3. ...



## 数据来源

1. 已有数据集
2. 爬虫



## 数据获取

- 小规模数据读取
- 大数据读取
- 实时数据读取



## 数据探索/数据处理/可视化

- 数理统计：方差、回归、因子、
- 数据趋势：
  - 集中趋势：分位数、众数、平均数、
  - 离中趋势：极差、方差/标准差、四分位距、离散系数
- 数据分布：
  - 数据偏态
  - 数据峰度
- 分布类型：
  - 正态分布
  - 卡方分布
  - t分布
  - F分布
- 数据合并
- 缺失值
  - 删除/填补
- 重复值（冗余）
  - 删除
- 异常值（错误）
  - 删除/修改/填补



## 数据探索/特征工程/可视化

- 特征类型
  - 数值型特征
    - 原始值
    - 离散化
      - 二值化
      - 分箱
    - 非线性变换
      - 对数变换
    - 特征缩放（标准化）
      - min-max
      - z-score
      - 归一化
  - 类别特征
    - 独热编码（one-hot）
    - 虚拟编码
    - 效果编码
- 特征分析
  - 单特征分析
    - 无用特征删除
    - 特征相关性分析
  - 多特征分析
    - 特征组合
    - 特征交互
  - 特征创建
    - 单特征转换
    - 多特征转换
  - 数据分布分析
  - 多重共线性
- 特征选择/特征提取
  - 过滤式：直接通过统计量分析筛掉特征
  - 包裹式：选取特征子集，根据模型评分选取特征
  - 嵌入式：输入全部特征数据到模型，根据模型的特征重要性（权值系数）排序筛选特征
- 降维
  - PCA
  - LDA
  - 随机投影
  - 特征聚合

## 数据分析/数据挖掘/可视化

### 数据

- 数据分布
  - 模型训练的潜在假设是训练集数据能代表全部数据（全体样本有一个未知分布的假设，要训练得到正确的模型，从全体样本空间采样得到的训练集应该满足同一分布）
  - 训练集的假设：独立同分布产生的
  - 模型测试的样本同样有该分布假设，且测试集应当尽量与训练集互斥（训练集中未出现、未使用）
- 特征空间维度和样本数量
  - 训练样本数量应该能覆盖整个特征空间，假设10个特征，每个特征取值有3个，则最小样本数目为3**10
- 数据不平衡

### 模型

- Logistic回归
- KNN
- 支持向量机
- Naive Bayes
- 决策树
- 随机森林
- 感知器
- 人工神经网络
- RVM或相关性向量机
- ...

### 损失函数和误差

- 损失函数
  - 0-1损失
  - 平方损失
  - 绝对损失
  - 对数损失
- 期望风险/经验风险/结构风险
  - 期望风险是对联合分布期望损失
  - 经验风险是对训练集的平均损失
  - 根据大数定律，当样本数量N趋于无穷时，经验风险趋于期望风险
  - 学习策略：经验风险最小化和结构风险最小化（平衡经验风险最小化和模型复杂度）
- 误差
  - 模型在训练集上的误差（平均损失）称为“训练误差”，即“经验误差”（结构误差）
  - 模型在测试集上的误差（平均损失）称为“测试误差”，即“泛化误差”，我们希望得到的是泛化误差最小的模型
  - 模型对未知数据的预测能力称为泛化能力

### 评估

- 训练集/验证集/测试集
  - 训练集：训练模型
  - 验证集：选择模型
  - 测试集：测试模型
- 过拟合/欠拟合；
- 偏差/方差
- 模型选择：这里指的不是单纯指选择LR或是SVM，而是包含同一模型不同参数下如何选择
  - 正则化（限制模型复杂度）
  - 交叉验证
    - 留出法
    - 交叉验证
    - 自助法
- 性能度量
  - 错误率和精度
  - 查准率和查全率
  - F-score
  - ROC、AUC、PR
  - 均方差
  - 代价敏感错误率
- 比较检验
  - 假设检验
  - 交叉验证t检验
  - friedman检验、Nemynyi检验

### 优化

- 调整超参
- 集成模型/模型融合



## 模型迭代





## C++或JAVA重写





# 业务和应用

## 计算机视觉



## 自然语言处理



## 语音识别



## 推荐系统



## 计算广告



## 智能游戏



# 工程能力

## 数据结构和算法



## 大数据处理



## 机器学习平台

sklearn

tensorflow

pytorch



## 并行计算



## 数据库和数据仓库



## 系统服务和架构